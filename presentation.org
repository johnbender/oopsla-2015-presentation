#+REVEAL_HEAD_PREAMBLE: <link rel="stylesheet" type="text/css" href="assets/style.css" />
#+REVEAL_ROOT: https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.1.0/
#+REVEAL_THEME: white
#+REVEAL_TRANS: none
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HLEVEL: 10
#+EXPORT_FILE_NAME: index
#+TITLE: Declarative Fence Insertion
#+AUTHOR:
#+EMAIL: johnbender@cs.ucla.edu
#+OPTIONS: num:nil toc:nil reveal_history:t reveal_control:nil reveal_mathjax:t
** mutex

   The Art of Multiprocessor Programming, 2.3.1

   #+INCLUDE: "code/LockOne.java" src java

** mutual exclusion proof

   The Art of Multiprocessor Programming, 2.3.1

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
>   flag[i] = true;
>   while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

** Bad execution
   | Thread 0          | Thread 1          |      |
   |-------------------+-------------------+------|
   | ~flag[1] : false~ |                   |      |
   |                   | ~flag[1] = true~  |      |
   |                   | ~flag[0] : false~ |      |
   | ~flag[0] = true~  |                   |      |
   |                   | enter cs          |      |
   | enter cs          |                   | bad! |

** ensuring correctness
   1. sequential consistency
     - not required/expensive
   2. ~volatile~ modifier
     - imprecise
   3. memory fences
     - imprecise

   #+BEGIN_QUOTE
   Pragma 2.3.1. In practice, the Boolean flag variables ... must all
   be declared ~volatile~ to work properly.
   #+END_QUOTE

   #+BEGIN_NOTES
   sequential consistency is expensive and not required by the proof

   volatile affects all writes to the modified variable, but we only
   care about on write in particular

   in C/C++ memory fences relate many instructions before and after,
   sacrificing information about the actual required behavior

   All of these are implementation details of a higher level concept
   #+END_NOTES

** execution order
   #+BEGIN_QUOTE
   The requirement that two instructions be seen to execute in the
   order they appear in the program.
   #+END_QUOTE

** algorithms: code *and* orders
   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
>   flag[i] = true;
>   while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   ${st(\mathtt{flag[i]}) \rightarrow ld(\mathtt{flag[j]})}$

* Problem Subtleties
  #+BEGIN_NOTES
  We have an idea of what we think algorithms should look like,
  what's standing in our way?
  #+END_NOTES
** cross platform
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;
     flag[i] = true;

     // for x86
     __asm__ ("mfence");
     // for arm
     __asm__ ("dmb");

     while (flag[j]) {} // wait
   }
   #+END_SRC

   #+BEGIN_NOTES
     assuming we're programming at the level of C/C++ we need to use an
     architecture appropriate fence instruction to ensure the two orders
     defined in the proof
   #+END_NOTES

** fence selection
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;
     flag[i] = true;

     // either will work in this case
     // `dmb st` is "faster"
     __asm__ ("dmb");
     __asm__ ("dmb st");

     while (flag[j]) {} // wait
   }
   #+END_SRC

   #+BEGIN_NOTES
     different paired instructions may require different fences,
     optimizing for performance
   #+END_NOTES

** existing fence(-likes)
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;

     // x86 cmpxchg has fence-like semantics
     CAS(flag[i], true);

     while (flag[j]) {} // wait
   }
   #+END_SRC

   #+BEGIN_NOTES
     there are other instructions like `cmpxhg` which have fence like
     semantics that we should account for (by avoiding adding more fences).
   #+END_NOTES

** TL2 STM Algorithm
   #+INCLUDE: "code/TxCommit.c" src c++

   #+BEGIN_NOTES
     TODO split up the following

     commit procedure for the tl2 software transactional memory algorithm
     writebackforward is where the actual writes to memory take place
     droplocks releases locks for the memory addresses for other commit calls to write
     macros provided for implementors to define arch appropriate fences

     1. bad to put a fence right after writebackforward (loop)
     2. bad to use a fence if ~TL2_EAGER~ is defined (will remove writebackforward)
     3. bad to use a fence for ~MEMBARSTST~ on x86
     4. fences/fence macros don't document their own reason for existence
   #+END_NOTES

** overlapping orders
* Algorithm

   #+BEGIN_SRC python
   # Insert : CFG x Arch x OrderSet -> CFG
   def Insert(G1, A, O1):

     # Elim : CFG x Arch x OrderSet -> OrderSet
     O2 = O1 \ Elim(G, A, O1)

     # Cut : CFG x OrderSet -> CutSet
     K  = Cut(G, O2)

     # Refine : CFG x CutSet -> CFG
     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   #+BEGIN_NOTES
     1. We eliminate orders which are enforced on the target
        architecture, e.g. a store -> store order on x86 is enforced
        by the architecture. *optimization*

     2. We find a multicut for the remaining orders and the control flow graph G

     3. We use the cut to insert fences on the cut set edges
   #+END_NOTES

** main theorem
   $\mathsf{Insert}(G, A, O), A \vDash O$

   #+BEGIN_NOTES
     Intuitively, if we have at least one "big hammer fence" for A
     that will work to keep any instructions we might pair from
     trading places in execution then Insert will enforce the orders
     we have defined by getting a fence between them on all possible
     execution paths

     We briefly discuss the subtlety introduced by fence selection in the paper
   #+END_NOTES

* Implementation
   [[file:./assets/images/impl-diagram.png]]

   #+BEGIN_NOTES
     - Our tool Parry takes an architecture specification, source and
       orders and provides source with fences to enforce those orders

     - Parry is built on top of LLVM's IR and wraps both Clang and
       LLVM's opt tool.

     - Edge elimination shrinks the control flow graph to speed up
       Elimination

     - Order elimination corresponds with Elim

     - Assigning cycle capacities ensures that we avoid placing fences
       in loops unless otherwise completely necessary
   #+END_NOTES

* Results
  TODO include tables?
** summary
   - x86 arm
   - two transaction memory algorithms
   - four classic lock free algorithms
   - match or better hand placed/selected fences
** performance
   - exponential time order elimination algorithm
   - linear time order elimination algorithm
   file:./assets/images/linear-perf.png

   - notes

     most of the time in processing is spent in generating the
     modified control flow graph in Python, everything else appeals to
     optimized C/C++ depedencies

** classic
   - matched all hand placed fences
** tl2
   - one fence saved!
** tl2 eager
   - one fence saved!
** rstm
   - notes about cmpxchg

* Related
** semantics
   - weak memory calculus from CMU
** recovering sequential consistency
   - Don't Sit on the Fence [Alglave]
   - Hiding relaxed memory consistency with a compiler [Lee]

   - notes

     all whole program

** enforcing arbitrary properties
   - Automatic inference of memory fences [Kuperstein]
   - Synthesis of memory fences via refinement propagation [Meshman]

   - notes

     all whole program
* Thanks!
