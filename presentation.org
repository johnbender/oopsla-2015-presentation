#+REVEAL_HEAD_PREAMBLE: <link rel="stylesheet" type="text/css" href="assets/style.css" />
#+REVEAL_ROOT: assets/reveal/
#+REVEAL_THEME: white
#+REVEAL_TRANS: none
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HLEVEL: 10
#+EXPORT_FILE_NAME: index
#+TITLE: Declarative Fence Insertion
#+AUTHOR: John Bender, Jens Palsberg - UCLA @@html: <br/> @@ Mohsen Lesani - MIT
#+EMAIL:
#+OPTIONS: num:nil toc:nil reveal_history:t reveal_control:nil reveal_mathjax:t
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+INCLUDE: "code/LockOne.java" src java

   #+BEGIN_NOTES
   Our work focuses on performance critical concurrent algorithms

   Here we have an example of one such algorithm from the art of multiproc
   programming

   It's a lock that's intended to guarantee mutual exclusion for exactly two
   threads
   #+END_NOTES

** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];
                                       ▲
  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
    flag[i] = true;
    while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   #+BEGIN_NOTES
   Here we have some example code from the art of multiproc
   programming

   It's lock that's intended to guarantee mutual exclusion for two
   threads
   #+END_NOTES
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
▶   int i = ThreadID.get();
    int j = i-1;
    flag[i] = true;
    while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC


   #+BEGIN_NOTES
   Here we have some example code from the art of multiproc
   programming

   It's lock that's intended to guarantee mutual exclusion for two
   threads
   #+END_NOTES
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
▶   int j = i-1;
    flag[i] = true;
    while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   #+BEGIN_NOTES
   Here we have some example code from the art of multiproc
   programming

   It's lock that's intended to guarantee mutual exclusion for two
   threads
   #+END_NOTES
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
▶   flag[i] = true;
    while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   #+BEGIN_NOTES
   Here we have some example code from the art of multiproc
   programming

   It's lock that's intended to guarantee mutual exclusion for two
   threads
   #+END_NOTES
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
    flag[i] = true;
▶   while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   #+BEGIN_NOTES
   Here we have some example code from the art of multiproc
   programming

   It's lock that's intended to guarantee mutual exclusion for two
   threads
   #+END_NOTES
** ~LockOne~ mutex
   The Art of Multiprocessor Programming, 2.3.1

   Maurice Herlihy & Nir Shavit, 2012

   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
▶   flag[i] = true;
▶   while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC

   #+BEGIN_NOTES
   These two lines are critical:

   - the first records an intent to enter a critical section guarded by the lock
     at the flag index corresponding to the thread id
   - the second checks the other thread's flag and spins until it's false (unlocked)

   The proof of mutual exclusion in the book requires that these two
   lines execute in program order

   More specifically, their interactions with memory must take effect
   in program order
   #+END_NOTES

** good execution

   | Thread 0          | Thread 1          |
   |-------------------+-------------------+
   | ~flag[0] = true~  |                   |
   | ~flag[1] : false~ |                   |
   |                   | ~flag[1] = true~  |
   |                   | ~flag[0] : true~  |
   |                   | spin              |
   | enter             |                   |

** bad execution

   | Thread 0                                                        | Thread 1          |
   |-----------------------------------------------------------------+-------------------|
   | @@html:<span class="hlght">@@ ~flag[0] = true~ @@html:</span>@@ |                   |
   | ~flag[1] : false~                                               |                   |
   |                                                                 | ~flag[1] = true~  |
   |                                                                 | ~flag[0] : true~  |
   |                                                                 | spin              |
   | enter                                                           |                   |

   #+BEGIN_NOTES
   As an example of a bad execution, the processor may "move" the
   store to thread 0's flag
   #+END_NOTES

** bad execution

   | Thread 0                                                         | Thread 1          |
   |------------------------------------------------------------------+-------------------|
   | ~flag[1] : false~                                                |                   |
   |                                                                  | ~flag[1] = true~  |
   |                                                                  | ~flag[0] : false~ |
   |                                                                  | enter             |
   | @@html:<span class="hlght">@@  ~flag[0] = true~ @@html:</span>@@ |                   |
   | enter                                                            |                   |

   #+BEGIN_NOTES
   This can happen when the processor determines that delaying the store
   is advantageous for performance reasons
   #+END_NOTES

** bad execution

   | Thread 0                                              | Thread 1                                              |
   |-------------------------------------------------------+-------------------------------------------------------|
   | ~flag[1] : false~                                     |                                                       |
   |                                                       | ~flag[1] = true~                                      |
   |                                                       | ~flag[0] : false~                                     |
   |                                                       | @@html:<span class="hlght">@@  enter @@html:</span>@@ |
   | ~flag[0] = true~                                      |                                                       |
   | @@html:<span class="hlght">@@  enter @@html:</span>@@ |                                                       |
   #+BEGIN_NOTES
   This ordering of operations allows both threads to enter the
   critical section

   Note that this is possible under extremely common memory models
   like Java, x86, ARM, and Power
   #+END_NOTES

** traditional solutions
   | solutions              | lost semantics | error prone | overkill |
   |------------------------+----------------+-------------+----------|
   | sequential consistency |                |             | ✓        |
   | ~volatile~ modifier    | ✓              |             | ✓        |
   | memory fences          | ✓              | ✓           |          |

   #+BEGIN_NOTES
   traditional solutions

   sequential consistency:
   - over: Many instructions can safely reorder for performance and the algorithm will work just fine

   volatile:
   - sem: establishes happens-before between many reads and writes
     when often there are only few important ones
   - overkill: again, we only need this property for a few operations,
     not every operation on the volatile variables

   memory fences:
   - sem: in C/C++ memory fences appearing in code relate many instructions before
     and after, again loosing information.

   - Also easy to mess up placement/required instruction

   - !! All of these are implementation details of a higher level concept
   #+END_NOTES

** execution order:
   #+BEGIN_QUOTE
   The requirement that two instructions appear to execute in program order.
   #+END_QUOTE

   #+BEGIN_NOTES
   That higher level concept is the execution order, which is ...
   #+END_NOTES

** algorithms = code + orders
   #+BEGIN_SRC java
class LockOne implements Lock {
  private boolean[] flag = new boolean[2];

  public void lock() {
    int i = ThreadID.get();
    int j = i-1;
▶   flag[i] = true;
▶   while (flag[j]) {}
  }

  public void unlock() {
    int i = ThreadID.get();
    flag[i] = false;
  }
}
   #+END_SRC
   @@html:
   <span class="plus">+</span>
   <div class="order">
   @@
   $\{ st(\mathtt{flag[i]}) \rightarrow ld(\mathtt{flag[j]}) \}$
   @@html:
   </div>
   @@

** Enforcing Orders

   How do we help implementers use orders?

   Fence insertion!
** previous approaches
   - Insert fences to...
     - enforce sequential consistency
     - enforce a specification
   - Whole program, O(2^n)

   #+BEGIN_NOTES
   SC: overkill in many cases

   Spec:

   Can be thought of as "finding the orders" necessary to ensure properties

   some properties don't work well as specification

   Orders exist as fragments of proofs which can't easily
   be translated into specifications, eg stm correctness

   Both: Whole program, don't scale well

   SC: Don't Sit On the Fence, CAV'14, alglave et al

   Spec: Automatic Inference of Memory Fences, FMCAD '10, Kuperstein et al

   #+END_NOTES
** our approach
   - Orders as part of the algorithm
   - Insert fences to enforce orders
   - Per-procedure
     - still O(2^n) but inputs are small

   #+BEGIN_NOTES
   This places our analysis at the procedure level.

   A Calculus for Relaxed Memory Models, PLDI 2015, Crary et al

   they built the semantics, we built the tool
   #+END_NOTES

* Fence Insertion Subtleties
  #+BEGIN_NOTES
  We have an idea of what we think algorithms should look like,
  what's standing in our way?
  #+END_NOTES
** many platforms
   #+BEGIN_SRC c++
   void lock() {
     int i = get_thread_id();
     int j = i-1;
     flag[i] = true;

   ▶ __asm__ ("mfence"); // x86
   ▶ __asm__ ("dmb");    // ARMv7

     while (flag[j]) {}
   }
   #+END_SRC

   #+BEGIN_NOTES
     assuming we're programming at the level of C/C++ we need to use an
     architecture appropriate fence instruction to ensure the two orders
     defined in the proof
   #+END_NOTES

** fence selection
   #+BEGIN_SRC c++
   void lock() {
     int i = get_thread_id();
     int j = i-1;
     flag[i] = true;

   ▶ __asm__ ("dmb");
   ▶ __asm__ ("dmb st"); // may be faster

     while (flag[j]) {}
   }
   #+END_SRC

   #+BEGIN_NOTES
     different paired instructions may require different fences,
     optimizing for performance
   #+END_NOTES

** existing fence(-likes)
   #+BEGIN_SRC c++
   void lock() {
     int i = get_thread_id();
     int j = i-1;

     // x86:   cmpxchg
     // ARMv7: ldrex/strex
   ▶ CAS(flag[i], false, true);

     while (flag[j]) {}
   }
   #+END_SRC

   #+BEGIN_NOTES
     there are other instructions like `cmpxhg` which have fence like
     semantics that we should account for (by avoiding adding more fences).
   #+END_NOTES

** TL2 STM Algorithm
   #+BEGIN_SRC c :results value :exports both
  ...

  # ifndef TL2_EAGER
  for (wr = logs; wr != end; wr++) {
    // write the deferred stores
▶   WriteBackForward(wr);
  }
  # endif

  // make stores visible before unlock
  MEMBARSTST();

  // release locks and increment version
  DropLocks(Self, wv);

  ...
   #+END_SRC

   #+BEGIN_NOTES
   - this is code from the tl2 transactional memory algorithm
   - avoiding details
   - there's a store to memory in the writebackforward
   #+END_NOTES

** TL2 STM Algorithm
   #+BEGIN_SRC c :results value :exports both
  ...

  # ifndef TL2_EAGER
  for (wr = logs; wr != end; wr++) {
    // write the deferred stores
    WriteBackForward(wr);
  }
  # endif

  // make stores visible before unlock
  MEMBARSTST();

  // release locks and increment version
▶ DropLocks(Self, wv);

  ...
   #+END_SRC

   #+BEGIN_NOTES
   - must happen before the store in droplocks for the algo to work
   #+END_NOTES
** TL2 STM Algorithm
   #+BEGIN_SRC c :results value :exports both
  ...

  # ifndef TL2_EAGER
  for (wr = logs; wr != end; wr++) {
    // write the deferred stores
    WriteBackForward(wr);
  }
  # endif

  // make stores visible before unlock
▶ MEMBARSTST();

  // release locks and increment version
  DropLocks(Self, wv);

  ...
   #+END_SRC

   #+BEGIN_NOTES
   - the authors of the code add these fence macros
   - provide a way to define platform appropriate solution to prevent
     stores from swapping
   #+END_NOTES
** code transformations
     #+BEGIN_SRC c :results value :exports both
  ...

  # ifndef TL2_EAGER
▶ for (wr = logs; wr != end; wr++) {
▶   // write the deferred stores
▶   WriteBackForward(wr);
▶ }
  # endif

  // make stores visible before unlock
  MEMBARSTST();

  // release locks and increment version
  DropLocks(Self, wv);

  ...
   #+END_SRC

   #+BEGIN_NOTES
   - if ~TL2_EAGER~ is defined will remove writebackforward
   - so the macro and fence becomes unnecessary
   #+END_NOTES

** faux order
   #+BEGIN_SRC c :results value :exports both
  ...

  # ifndef TL2_EAGER
  for (wr = logs; wr != end; wr++) {
    // write the deferred stores
▶   WriteBackForward(wr);
  }
  # endif

  // make stores visible before unlock
  MEMBARSTST();

  // release locks and increment version
▶ DropLocks(Self, wv);

  ...
   #+END_SRC

   #+BEGIN_NOTES
   - more generally the implementers really wanted to define an order here
   - by using a fence macro anyone coming to the code has to have the algorithm
     spec in hand to determine why that fence was placed
   #+END_NOTES
* Algorithm
** algorithm
   #+BEGIN_SRC python
   def Insert(G1, A, O1):
         ▲
     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]
 5 [label="ld(w)", color="gray"]
 7 [label="st(w)", color="gray"]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 5 -> m [style=invis]
 m -> 7 [style=invis]
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 5 -> 7 [color="gray"]

 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - our algorithm insert
   - left code, right inputs except for the architecture
   #+END_NOTES

** control flow graph
   #+BEGIN_SRC python
   def Insert(G1, A, O1):
               ▲
     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-fst-input.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)", color="red"]
 2 [label="st(x)", color="red"]
 3 [label="st(w)", color="red"]
 4 [label="ld(z)", color="red"]

 1 -> 2 [color="red"]
 2 -> 3 [color="red"]
 3 -> 4 [color="red"]

 node[shape=circle]
 5 [label="ld(w)", color="gray"]
 7 [label="st(w)", color="gray"]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 5 -> m [style=invis]
 m -> 7 [style=invis]
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 5 -> 7 [color="gray"]

 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC

   #+RESULTS:
   [[file:assets/images/full-graph-fst-input.png]]

   @@html: </div>@@

   #+BEGIN_NOTES
   - control flow graph for some simple procedure
   #+END_NOTES
** architecture spec
   #+BEGIN_SRC python
   def Insert(G1, A, O1):
                  ▲
     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]
 5 [label="ld(w)", color="gray"]
 7 [label="st(w)", color="gray"]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 5 -> m [style=invis]
 m -> 7 [style=invis]
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 5 -> 7 [color="gray"]

 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - an architecture specification not pictured here
   - it tells us what the architecture WONT reorder
   - we'll assume ARM for the sake of the example
   #+END_NOTES
** orders
   #+BEGIN_SRC python
   def Insert(G1, A, O1):
                      ▲
     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-third-input.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]
 5 [label="ld(w)", color="red"]
 7 [label="st(w)", color="red"]

 9 [label="st(x)", color="red"]
 10 [label="st(w)", color="red"]

 6 [label="st(x)", color="red"]
 8 [label="ld(z)", color="red"]

 node[shape=point style=invis]
 splines=line
 5 -> m [style=invis]
 m -> 7 [style=invis]
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 5 -> 7 [color="red"]

 9 -> 10 [color="red"]

 6 -> 8 [color="red"]
}
   #+END_SRC

   #+RESULTS:
   [[file:assets/images/full-graph-third-input.png]]

   @@html: </div>@@

   #+BEGIN_NOTES
   - set of orders that need to be enforced
   #+END_NOTES
** order elimination
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

   ▶ O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-elim.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]
 5 [label="ld(w)", color="red"]
 7 [label="st(w)", color="red"]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 5 -> m [style=invis]
 m -> 7 [style=invis]
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 5 -> 7 [color="red"]

 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - first step is order elimination
   - we want to avoid inserting fences where they are unnecessary
   - on arm (and every other architecture) a load won't move past a store to the same address
   #+END_NOTES

** order elimination
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

   ▶ O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-elim-after.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - so we can safely discard that order
   #+END_NOTES

** fence position
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

     O2 = O1 \ Elim(G, A, O1)

   ▶ K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-cut.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - the next step is finding good places for fences that will enforce the orders
   #+END_NOTES

** fence position
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

     O2 = O1 \ Elim(G, A, O1)

   ▶ K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-cut-highlight.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3
 3 -> 4

 node[shape=circle]

 9 [label="st(x)", color="red"]
 10 [label="st(w)", color="red"]

 6 [label="st(x)", color="red"]
 8 [label="ld(z)", color="red"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="red"]

 6 -> 8 [color="red"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - we consider all the orders
   - use multicut to find an optimal set of edges to separate the sources from the sinks
   #+END_NOTES

** fence position
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

     O2 = O1 \ Elim(G, A, O1)

   ▶ K  = Cut(G1, O2)

     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-cut-highlight-2.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3 [color="red"]
 3 -> 4

 node[shape=circle]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - so our cut set K is just the one edge between the two stores
   #+END_NOTES

** fence placement
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

   ▶ G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-refine.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]

 1 -> 2
 2 -> 3 [color="red"]
 3 -> 4

 node[shape=circle]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

   #+BEGIN_NOTES
   - finally we use the cut set to place fences in the control flow graph
   #+END_NOTES

** fence placement
   #+BEGIN_SRC python
   def Insert(G1, A, O1):

     O2 = O1 \ Elim(G, A, O1)

     K  = Cut(G1, O2)

   ▶ G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   @@html: <div class="algo-graph">@@
   #+BEGIN_SRC dot :file assets/images/full-graph-refine-apply.png :exports results
digraph a {
 splines=line
 node [shape = circle];
 1 [label="ld(w)"]
 2 [label="st(x)"]
 3 [label="st(w)"]
 4 [label="ld(z)"]
 5 [label="fence" color="red"]

 1 -> 2
 3 -> 4
 2 -> 5 [color="red"]
 5 -> 3 [color="red"]

 node[shape=circle]

 9 [label="st(x)", color="gray"]
 10 [label="st(w)", color="gray"]

 6 [label="st(x)", color="gray"]
 8 [label="ld(z)", color="gray"]

 node[shape=point style=invis]
 splines=line
 n -> 6 [style=invis]
 6 -> o [style=invis]
 o -> 8 [style=invis]
 p -> 9 [style=invis]


 9 -> 10 [color="gray"]

 6 -> 8 [color="gray"]
}
   #+END_SRC
   @@html: </div>@@

** main theorem
   $\mathsf{Insert}(G, A, O), A \vDash O$

   #+BEGIN_NOTES
   intuitively, Given a graph, architecture and orders ~insert~
   will produce a graph that, assuming the same architecture
   will enforce the orders
   #+END_NOTES

# * Implementation
#    [[file:./assets/images/impl-diagram.png]]

#    #+BEGIN_NOTES
#      - Our tool Parry takes an architecture specification, source and
#        orders and provides source with fences to enforce those orders

#      - Parry is built on top of LLVM's IR and wraps both Clang and
#        LLVM's opt tool.

#      - Edge elimination shrinks the control flow graph to speed up
#        Elimination

#      - Order elimination corresponds with Elim

#      - Assigning cycle capacities ensures that we avoid placing fences
#        in loops unless otherwise completely necessary
#    #+END_NOTES

* Results/Parry
** benchmark: classic algorithms
   - from Algave et al '14
   - x86 and ARMv7
   - 4 lock free algorithms
** benchmark: STM algorithms
   - TL2/TL2 Eager
   - Rochester ByteEager (TLRW)
   - x86 and ARMv7
   - compared with hand placed fences (baseline)
     - fence placement and count
     - STAMP performance benchmarks
   #+BEGIN_NOTES
   - TL2/TL2 Eager
     - included with STAMP Benchmarks
   - RSTM ByteEager
     - part of Rochester STM Algorithm Suite

   - TL2 is the largest in terms of procedure size
   - TxCommit has nearly 400 nodes
   - Just under 30s to run for the 3 procedures in TL2 that have orders
   #+END_NOTES
# ** execution time
#    file:./assets/images/linear-perf.png

#    #+BEGIN_NOTES
#    - exponential time order elimination algorithm
#    - linear time order elimination algorithm

#    most of the time in processing is spent in generating the
#    modified control flow graph in Python, everything else appeals to
#    optimized C/C++ depedencies
#    #+END_NOTES

# ** classic
#    |          |                             | *x86*        | *ARMv7*      |
#    | *Dekker* | 8 $\xrightarrow{st,ld}$ 9   | 8: ~mfence~  | 8: ~dmb st~  |
#    |          | 13 $\xrightarrow{st,ld}$ 9  | 13: ~mfence~ | 13: ~dmb st~ |
#    |          | 25 $\xrightarrow{st,ld}$ 26 | 25: ~mfence~ | 25: ~dmb st~ |
#    |          | 30 $\xrightarrow{st,ld}$ 26 | 30: ~mfence~ | 30: ~dmb st~ |
#    |          |                             |              |              |
#    | *Parker* | 44 $\xrightarrow{st,*}$ 46  | 44: ~mfence~ | 44: ~dmb st~ |

#    #+BEGIN_NOTES
#    For the classic algorithms we fences were placed in expected locations

#    Explain how to read the table.
#    #+END_NOTES

# ** classic
#    |            |                             | *x86*        | *ARMv7*      |
#    | *Lamport*  | 8 $\xrightarrow{st,ld}$ 9   | 8: ~mfence~  | 8: ~dmb st~  |
#    |            | 14 $\xrightarrow{st,ld}$ 15 | 14: ~mfence~ | 14: ~dmb st~ |
#    |            | 31 $\xrightarrow{st,ld}$ 32 | 31: ~mfence~ | 31: ~dmb st~ |
#    |            | 37 $\xrightarrow{st,ld}$ 38 | 37: ~mfence~ | 37: ~dmb st~ |
#    |            |                             |              |              |
#    | *Peterson* | 5 $\xrightarrow{st,ld}$ 7   | 5: ~mfence~  | 5: ~dmb st~  |
#    |            | 14 $\xrightarrow{st,ld}$ 16 | 14: ~mfence~ | 14: ~dmb st~ |

** tl2 - ARMv7
   | *~TxStore~*                     | baseline                                                      | ours                                                          |
   | 1886 $\xrightarrow{ld,ld}$ 1923 | @@html:<span class="hlght">@@ 1920: ~dmb~ @@html:</span>@@    | @@html:<span class="hlght">@@ 1886: ~dmb~ @@html:</span>@@    |


   #+BEGIN_NOTES
   TxStore: we placed our fence "further up" the control flow graph,
   this is dues to the way the multicut algorithm handles a sequence
   of similarly weighted edges, choosing the first
   #+END_NOTES

** tl2 eager - ARMv7
   | *~TxCommit~*                    | baseline                                                      | ours                                              |
   | 760 $\xrightarrow{st,st}$ 1413  | @@html:<span class="hlght">@@ 1669: ~dmb st~ @@html:</span>@@ | @@html:<span class="hlght">@@  — @@html:</span>@@ |

   #+BEGIN_NOTES
   Not that due to the ifdefs we saw in the example earlier we are
   able to eliminate the stst fence at line 1669 on arm
   #+END_NOTES

** rstm - ARMv7
   | *~read_rw~*                   | baseline                                                          | ours                                                         |
   | 163 $\xrightarrow{st,ld}$ 165 | @@html:<span class="hlght">@@ 163: ~ldrex/strex~ @@html:</span>@@ | @@html:<span class="hlght">@@ 163: ~dmb st~ @@html:</span>@@ |

   #+BEGIN_NOTES
   in the ~read_rw~ method of the RSTM ByteEager algorithm they use a
   compare and swap to enforce a store/store order
   #+END_NOTES

** tl2 performance
   file:./assets/images/stamp-arm-tl2.png
** rstm performance
   file:./assets/images/stamp-arm-rstm.png
# * Related
# ** semantics
#    - A Calculus for Relaxed Memory, Crary and Sullivan
# ** sequential consistency
#    - Don't Sit on the Fence, Alglave et al
#    - Hiding relaxed memory consistency with a compiler, Lee et al
# ** specification
#    - Automatic Inference of Memory Fences, Kuperstein et al
#    - Synthesis of Memory Fences via Refinement Propagation, Meshman et al

* algorithms = code + orders
  - Describe the algorithm behavior
  - Let the compiler enforce the orders
* Thanks!
