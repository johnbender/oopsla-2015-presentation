#+HTML_HEAD:   <link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.5/readable/bootstrap.min.css" rel="stylesheet">
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="assets/style.css" />
#+OPTIONS: num:nil toc:nil reveal_history:t reveal_control:nil reveal_mathjax:t
* section 1 (Introduction)
** loose definition
   #+BEGIN_QUOTE
   The requirement that two instructions be seen to execute in the
   order they appear in the program.
   #+END_QUOTE

** the art of multiprocessor programming, 2.3.1 ~LockOne~ class
   #+INCLUDE: "code/LockOne.java" src java

   - notes

     - Two threads only
     - shared instance of the lock
     - each thread waits for the other thread's flag to be false then
       enters critical section

** mutual exclusion proof requires two orders
   #+BEGIN_EXAMPLE
   writeA(flag[A] = true)  -> readA(flag[B] == false) -> CSA (2.3.1)
   writeB(flag[B] = true)  -> readB(flag[A] == false) -> CSB (2.3.2)
   #+END_EXAMPLE

   - notes

     proof by contradiction: CSA -/-> CSB and CSB -/-> CSA

     ie they are concurrent

     2.3.1 and 2.3.2 are *assumed* in the proof of mutual exclusion,
     which may not hold under weak memory models. eg java's memory
     model or in an unmanaged language the memory models of
     x86, arm, power.

** store buffering in LockOne
   | Thread 0          | Thread 1          |                 |
   |-------------------+-------------------+-----------------|
   | ~flag[0] = true~  |                   | buffered        |
   | ~flag[1] : false~ |                   |                 |
   |                   | ~flag[1] = true~  |                 |
   |                   | ~flag[0] : false~ | unflushed value |
   |                   | enter cs          |                 |
   | enter cs          |                   | bad!            |

   - notes

     for example, in java the write to ~flag[0]~ might be delayed in a
     store buffer so the read in the other thread returns its previous
     value allowing both threads to enter the critical section

** traditionally solved with fences or volatile variables/class members

   #+BEGIN_QUOTE
   In practice, the Boolean flag variables ... must all
   be declared volatile to work properly.
   #+END_QUOTE

   - notes

     fences and volatile variables are the implementation details of
     more a precise tool: declarative orders.

** algorithms code *and* orders

   #+BEGIN_EXAMPLE
   writeA(flag[A] = true) -> readA(flag[B] == false)
   writeB(flag[B] = true) -> readB(flag[A] == false)
   #+END_EXAMPLE

   - notes

   In our work we propose that these orders be specified as part of
   the algorithm and that the responsibility for enforcing them be
   delegated to the compiler.

* section 2 (Problem)
  TODO should we add more bad executions?

  - notes

    lets look at some subtleties that go along with using fences to
    get a better sense for why we think a compiler should handle this
    task

** cross platform
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;
     flag[i] = true;

     // for x86
     __asm__ ("mfence");
     // for arm
     __asm__ ("dmb");

     while (flag[j]) {} // wait
   }
   #+END_SRC

   - notes

     assuming we're programming at the level of C/C++ we need to use an
     architecture appropriate fence instruction to ensure the two orders
     defined in the proof

** fence selection
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;
     flag[i] = true;

     // either will work in this case
     // `dmb st` is "faster"
     __asm__ ("dmb");
     __asm__ ("dmb st");

     while (flag[j]) {} // wait
   }
   #+END_SRC

   - notes

     different paired instructions may require different fences,
     optimizing for performance

** existing fence(-likes)
   #+BEGIN_SRC c++
   void lock() {
     int i = ThreadID.get();
     int j = i-1;

     // x86 cmpxchg has fence-like semantics
     CAS(flag[i], true);

     while (flag[j]) {} // wait
   }
   #+END_SRC

   - notes

     there are other instructions like `cmpxhg` which have fence like
     semantics that we should account for (by avoiding adding more fences).

** TL2 STM Algorithm
   #+INCLUDE: "code/TxCommit.c" src c++

   - notes

     TODO split up the following

     commit procedure for the tl2 software transactional memory algorithm
     writebackforward is where the actual writes to memory take place
     droplocks releases locks for the memory addresses for other commit calls to write
     macros provided for implementors to define arch appropriate fences

     1. bad to put a fence right after writebackforward (loop)
     2. bad to use a fence if ~TL2_EAGER~ is defined (will remove writebackforward)
     3. bad to use a fence for ~MEMBARSTST~ on x86
     4. fences/fence macros don't document their own reason for existence

** orders not fences
   Leave the details to the compiler!

   - notes

     determining the need for/placement/type of fences is difficult
     and the results convey very little information in the code

     we should use orders and delegate the work to the compiler!

* section 3 (Algorithm)
  - notes

** algorithm
   #+BEGIN_SRC python
   # Insert : CFG x Arch x OrderSet -> CFG
   def Insert(G1, A, O1):

     # Elim : CFG x Arch x OrderSet -> OrderSet
     O2 = O1 \ Elim(G, A, O1)

     # Cut : CFG x OrderSet -> CutSet
     K  = Cut(G, O2)

     # Refine : CFG x CutSet -> CFG
     G2 = Refine(G1, K)

     return G2
   end
   #+END_SRC

   - notes

     1. We eliminate orders which are enforced on the target
        architecture, e.g. a store -> store order on x86 is enforced
        by the architecture. *optimization*

     2. We find a multicut for the remaining orders and the control flow graph G

     3. We use the cut to insert fences on the cut set edges

** theorem 1

   #+BEGIN_SRC
   Insert(G, A, O), A |= O.
   #+END_SRC

   Removed the ~fany~ requirement for clarity

   - notes

     Intuitively, if we have at least one "big hammer fence" for A
     that will work to keep any instructions we might pair from
     trading places in execution then Insert will enforce the orders
     we have defined by getting a fence between them on all possible
     execution paths

     We briefly discuss the subtlety introduced by fence selection in the paper

* section 4 (Implementation)
** diagram
   [[file:./assets/images/impl-diagram.png]]

   - notes

     - Our tool Parry takes an architecture specification, source and
       orders and provides source with fences to enforce those orders

     - Parry is built on top of LLVM's IR and wraps both Clang and
       LLVM's opt tool.

     - Edge elimination shrinks the control flow graph to speed up
       Elimination

     - Order elimination corresponds with Elim

     - Assigning cycle capacities ensures that we avoid placing fences
       in loops unless otherwise completely necessary

* section 5 (Experiments)
  TODO include tables?
** summary
   - x86 arm
   - two transaction memory algorithms
   - four classic lock free algorithms
   - match or better hand placed/selected fences
** performance
   - exponential time order elimination algorithm
   - linear time order elimination algorithm
   file:./assets/images/linear-perf.png

   - notes

     most of the time in processing is spent in generating the
     modified control flow graph in Python, everything else appeals to
     optimized C/C++ depedencies

** classic
   - matched all hand placed fences
** tl2
   - one fence saved!
** tl2 eager
   - one fence saved!
** rstm
   - notes about cmpxchg

* section 6 (Related)
** semantics
   - weak memory calculus from CMU
** recovering sequential consistency
   - Don't Sit on the Fence [Alglave]
   - Hiding relaxed memory consistency with a compiler [Lee]

   - notes

     all whole program

** enforcing arbitrary properties
   - Automatic inference of memory fences [Kuperstein]
   - Synthesis of memory fences via refinement propagation [Meshman]

   - notes

     all whole program

* feedback
** Jens
   - section 1
     - use a different arrow for happens before
     - get rid of CSA/CSB or explain thoroughly
     - use our notation for the happens before
     - drop difference between happens before/orders
     - if we read the code under seq consistency, then the proof goes
       through but weaker memory models will work with some assistance
     - these orders which are implied by seq consistency can be taken as
       part of the spec
     - orders and algorithms slide using our notation
     - what would we do with weaker memory models

     - traditionally solved
       - runtime sequential consistency
       - proof doesn't require SC!
       - just those two instructions
       - targeted SC
       - quote about volatile
       - code sample with fence
       - big hammers
       - instead lets just use the proof as a spec
     - algorithms = code + orders
       - Hurlehy should use orders
   - section 2
     - fence insertion problem
     - related work?
       - whole program, don't scale
     - what do we get out of orders from the programmer
       - per procedure
     - so is there anything left to do at the procedure level
       - show that it's hard
     - algorithm is still 2^n
     - problem input size are small
   - section 3
     - requires arch spec, discuss
     - add dot graph from section 3 of the paper
     - put graphs,orders,architectures to the right of the code and
       step through transformations to both as the algorithm proceeds
   - section 5
     - methodology is key
       - go into detail
       - benchmarks come from other people
       - stamp for stm
     - first paper that does fence insertion for STM
       - scalability
     - say three stm algorithms
     - discuss our approach
       - removing fence macros
     - performance of the algorithms with our placements
     - one or at most two tables about output
** Jens 2
   - names and affiliations
   - add maurice herlihy/shavit and year
   - work on execution order definition, simplify, reduce verbs
   - previous approaches, add paper
     - "insert fences to..." (two approaches)
     - e.g. first name et al, conf year
     - recover vs enforce, check papers
     - whole program is 0(2^n)
   - our approach
     - insert fences to enforce orders
     - reference to CMU paper
     - we do the work, they have the semantics PLDI etc
   - make clear that the problem is fence insertion
   - problem subt
     - arrows to highlight code to look at
   - place fences
     - make sure to highlight orders
   - Classic Algorithms => Benchmarks: Classic Algorithms
   - STM Algorithms => Benchmark: STM Algorithms
     - much much harder!
     - notable for difficulty
   - maybe remove classic
   - results, focus on arm
   - maybe the semantics
   - move related work to "previous approaches
     - has to be fast
     - conference and year
   - conclusion with take home message
     - "stop writing your lock free algorithms without orders", only positive
** Jens 3
   - make the order notation more prominent
   - mention paper in slides about other approaches if not talked about
   - "ask programmer for ..." => "orders should be part of the algorithm"
   - put conferences with related work
   - remove related work
   - mention tool runtime for each set of benchmarks
     - loc and seconds
     - doesn't have to be on the slide
   - slogan: algorithm = code + orders
     - let the compiler enforce the orders
   - after talk tomorrow, revise and send Mohsen an email
** labmates
   - target audience for this talk
   - problems that arise in the domain
   - for performance critical concurrent applications
     - "and this is an example"
   - often cross platform
   - more high level
   - mention why operations can be reordered
     - on bad execution slides
     - store buffering
     - ooe
     - reason is performance
   - sc eliminates all reorderings
   - just say "specs not expressive enough for the algorithms we consider"
   - algorithm, don't say multicut or cutset
   - algorithm, explain cfg
   - the graph and nodes are confusing
** mohsen
   - update orders on fence insert
   - mention dekker
   - only guarantees mutual exclusion
   - safety not progress
   - too many details in exec example
   - explain semantics better
     - part of the algorithm definition is lost
     - find something else for semantics
     - logic
   - repeat performance sensitivity when talking about sc
   - pair of line number for notation in  alg = code + orders
   - previous work two authors, et all and conf abbreviation full year
   - add cmu paper in our approach (see also)
   - talk about cross platform approach in our approach
   - refine how we are different
   - enforcing orders include diagram that illustrates cross platform
   - explain stores in procedures for tl2 snippet
   - highlight one of the orders as an example
   - mention multicut
   - make note of cross platform issues in order elim
   - take time and explain theorem slide more
   - explain first table
   - different line numbers, straight line execution
   - explain last bar graph short and sweet
     - "the better we describe an architecture to our compiler the better our result"

   - last slide, "solves the long standing problem of porting TM algorithms"
   - take points and move to our approach
   - much larger fonts
